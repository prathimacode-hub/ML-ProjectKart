{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('electronics_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>1999-09-18</td>\n",
       "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2013-10-23</td>\n",
       "      <td>Pages and pages of introspection, in the style...</td>\n",
       "      <td>A stream of consciousness novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>2008-09-02</td>\n",
       "      <td>This is the kind of novel to read when you hav...</td>\n",
       "      <td>I'm a huge fan of the author and this one did ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>2000-09-04</td>\n",
       "      <td>What gorgeous language! What an incredible wri...</td>\n",
       "      <td>The most beautiful book I have ever read!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2000-02-04</td>\n",
       "      <td>I was taken in by reviews that compared this b...</td>\n",
       "      <td>A dissenting view--In part.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2010-06-17</td>\n",
       "      <td>How can you tell that these things are actuall...</td>\n",
       "      <td>okay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>2010-05-24</td>\n",
       "      <td>I was extremely pleased with how well this cle...</td>\n",
       "      <td>Works well, but strangely</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>2010-02-06</td>\n",
       "      <td>this product was wonderful,i have cd player in...</td>\n",
       "      <td>maxwell cd345 cd laser lens cleaner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>5</td>\n",
       "      <td>19</td>\n",
       "      <td>True</td>\n",
       "      <td>2009-10-01</td>\n",
       "      <td>This is one of those products where you can ne...</td>\n",
       "      <td>Works Well as Far as I Can Tell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2015-07-28</td>\n",
       "      <td>Good quality.</td>\n",
       "      <td>Four Stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      overall  vote  verified  reviewTime  \\\n",
       "0           5    67      True  1999-09-18   \n",
       "1           3     5      True  2013-10-23   \n",
       "2           5     4      True  2008-09-02   \n",
       "3           5    13      True  2000-09-04   \n",
       "4           3     8      True  2000-02-04   \n",
       "...       ...   ...       ...         ...   \n",
       "4995        3     0      True  2010-06-17   \n",
       "4996        5     7      True  2010-05-24   \n",
       "4997        5    10      True  2010-02-06   \n",
       "4998        5    19      True  2009-10-01   \n",
       "4999        4     0      True  2015-07-28   \n",
       "\n",
       "                                             reviewText  \\\n",
       "0     This is the best novel I have read in 2 or 3 y...   \n",
       "1     Pages and pages of introspection, in the style...   \n",
       "2     This is the kind of novel to read when you hav...   \n",
       "3     What gorgeous language! What an incredible wri...   \n",
       "4     I was taken in by reviews that compared this b...   \n",
       "...                                                 ...   \n",
       "4995  How can you tell that these things are actuall...   \n",
       "4996  I was extremely pleased with how well this cle...   \n",
       "4997  this product was wonderful,i have cd player in...   \n",
       "4998  This is one of those products where you can ne...   \n",
       "4999                                      Good quality.   \n",
       "\n",
       "                                                summary  \n",
       "0                                        A star is born  \n",
       "1                       A stream of consciousness novel  \n",
       "2     I'm a huge fan of the author and this one did ...  \n",
       "3             The most beautiful book I have ever read!  \n",
       "4                           A dissenting view--In part.  \n",
       "...                                                 ...  \n",
       "4995                                               okay  \n",
       "4996                          Works well, but strangely  \n",
       "4997                maxwell cd345 cd laser lens cleaner  \n",
       "4998                    Works Well as Far as I Can Tell  \n",
       "4999                                         Four Stars  \n",
       "\n",
       "[5000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import string\n",
    "import warnings\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from nltk import tokenize,WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['review','sentiment']]=df[['reviewText','overall']]\n",
    "\n",
    "df=df[['review', 'sentiment']]\n",
    "\n",
    "df['sentiment']=df['sentiment'].replace([1,2,3,4,5],[0,0,0,1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pages and pages of introspection, in the style...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the kind of novel to read when you hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What gorgeous language! What an incredible wri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was taken in by reviews that compared this b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>How can you tell that these things are actuall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>I was extremely pleased with how well this cle...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>this product was wonderful,i have cd player in...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>This is one of those products where you can ne...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>Good quality.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment\n",
       "0     This is the best novel I have read in 2 or 3 y...          1\n",
       "1     Pages and pages of introspection, in the style...          0\n",
       "2     This is the kind of novel to read when you hav...          1\n",
       "3     What gorgeous language! What an incredible wri...          1\n",
       "4     I was taken in by reviews that compared this b...          0\n",
       "...                                                 ...        ...\n",
       "4995  How can you tell that these things are actuall...          0\n",
       "4996  I was extremely pleased with how well this cle...          1\n",
       "4997  this product was wonderful,i have cd player in...          1\n",
       "4998  This is one of those products where you can ne...          1\n",
       "4999                                      Good quality.          1\n",
       "\n",
       "[5000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df['sentiment'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords1 = list(stopwords.words('english'))+list(punctuation) \n",
    "\n",
    "ps=PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "   \n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have be work on my skill\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def lemmatize_sentence(sentence):  \n",
    "   \n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence)) \n",
    "   \n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "\n",
    "   \n",
    "    lemmatized_sentence = []      \n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "       \n",
    "        else:       \n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "\n",
    "   \n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "print(lemmatize_sentence(\" i have been working on my skills \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pages and pages of introspection, in the style of writers like Henry James.  I like this kind of  novels and the writer occasionally delights me with her descriptions and observations.  But it\\'s way too repetitious for me and, I think, some parts could have been cut out while still preserving, and probably more tightly crystallizing, the themes and \"truths\" within the story.\\n\\nIt\\'s a story I could relate to but I wish it hadn\\'t been too tedious to read.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages and page of introspection , in the style of writer like Henry James . I like this kind of novel and the writer occasionally delight me with her description and observation . But it 's way too repetitious for me and , I think , some part could have be cut out while still preserve , and probably more tightly crystallize , the theme and `` truth '' within the story . It 's a story I could relate to but I wish it have n't be too tedious to read .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(lemmatize_sentence(df['review'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(a):\n",
    "    return  ' '.join([i.lower() for i in tokenize.word_tokenize(a) if i.lower() not in stopwords1])\n",
    " \n",
    "   \n",
    "    if len(ls)>2:\n",
    "        val= ' '.join(ls)\n",
    "        return val\n",
    "    else :\n",
    "        return None\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_lemma(a):\n",
    "    val= ' '.join([lemmatizer.lemmatize(i.lower(),pos = 'v') for i in tokenize.word_tokenize(a) if i.lower() not in stopwords1])\n",
    "    return val\n",
    "\n",
    "\n",
    "\n",
    "def clean_text_stem(a):   \n",
    "    val= ' '.join([ps.stem(i.lower()) for i in tokenize.word_tokenize(a) if i.lower() not in stopwords1])\n",
    "    return val\n",
    "\n",
    "df['clean_txt'] = df['review'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best novel read 2 3 years everything fiction -...</td>\n",
       "      <td>1</td>\n",
       "      <td>best novel read 2 3 years everything fiction -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pages pages introspection style writers like h...</td>\n",
       "      <td>0</td>\n",
       "      <td>pages pages introspection style writers like h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kind novel read time lose book days possibly w...</td>\n",
       "      <td>1</td>\n",
       "      <td>kind novel read time lose book days possibly w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gorgeous language incredible writer last life ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gorgeous language incredible writer last life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taken reviews compared book leopard promised b...</td>\n",
       "      <td>0</td>\n",
       "      <td>taken reviews compared book leopard promised b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>tell things actually cleaning dvd player n't p...</td>\n",
       "      <td>0</td>\n",
       "      <td>tell things actually cleaning dvd player n't p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>extremely pleased well cleaned cd player lens ...</td>\n",
       "      <td>1</td>\n",
       "      <td>extremely pleased well cleaned cd player lens ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>product wonderful cd player basement quit play...</td>\n",
       "      <td>1</td>\n",
       "      <td>product wonderful cd player basement quit play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>one products never completely sure anything fi...</td>\n",
       "      <td>1</td>\n",
       "      <td>one products never completely sure anything fi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>good quality</td>\n",
       "      <td>1</td>\n",
       "      <td>good quality</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 review  sentiment  \\\n",
       "0     best novel read 2 3 years everything fiction -...          1   \n",
       "1     pages pages introspection style writers like h...          0   \n",
       "2     kind novel read time lose book days possibly w...          1   \n",
       "3     gorgeous language incredible writer last life ...          1   \n",
       "4     taken reviews compared book leopard promised b...          0   \n",
       "...                                                 ...        ...   \n",
       "4995  tell things actually cleaning dvd player n't p...          0   \n",
       "4996  extremely pleased well cleaned cd player lens ...          1   \n",
       "4997  product wonderful cd player basement quit play...          1   \n",
       "4998  one products never completely sure anything fi...          1   \n",
       "4999                                       good quality          1   \n",
       "\n",
       "                                              clean_txt  \n",
       "0     best novel read 2 3 years everything fiction -...  \n",
       "1     pages pages introspection style writers like h...  \n",
       "2     kind novel read time lose book days possibly w...  \n",
       "3     gorgeous language incredible writer last life ...  \n",
       "4     taken reviews compared book leopard promised b...  \n",
       "...                                                 ...  \n",
       "4995  tell things actually cleaning dvd player n't p...  \n",
       "4996  extremely pleased well cleaned cd player lens ...  \n",
       "4997  product wonderful cd player basement quit play...  \n",
       "4998  one products never completely sure anything fi...  \n",
       "4999                                       good quality  \n",
       "\n",
       "[5000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']=df['clean_txt']\n",
    "\n",
    "df.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4000,) (1000,) (4000,) (1000,)\n",
      "[ 843 3157]\n",
      "[159 841]\n"
     ]
    }
   ],
   "source": [
    "df1=df[['review', 'sentiment']]\n",
    "\n",
    "df=df1\n",
    "\n",
    "def simple_split(df,y,l,sm=0.8):\n",
    "    if sm>0 and sm<1.0:\n",
    "        n=int(sm*l)\n",
    "    else:\n",
    "        n=int(sm)\n",
    "    X_train=df[:n].copy()\n",
    "    X_test=df[n:].copy()\n",
    "    y_train=y[:n].copy()\n",
    "    y_test=y[n:].copy()\n",
    "    return X_train,X_test,y_train,y_test\n",
    "        \n",
    "\n",
    "v=CountVectorizer()\n",
    "\n",
    "X_train,X_test,y_train,y_test=simple_split(df.review, df.sentiment, len(df))\n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "print(np.bincount(y_train))\n",
    "\n",
    "print(np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression\")\n",
    "clf2=LogisticRegression(solver=\"lbfgs\")\n",
    "model=Pipeline([('vectorizer',v),('classifier',clf2)])\n",
    "model.fit(X_train, y_train)\n",
    "p=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 69  48]\n",
      " [ 90 793]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(p,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.862"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(p, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decission Tree Classifier\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Decission Tree Classifier\")\n",
    "c=tree.DecisionTreeClassifier()\n",
    "model2=Pipeline([('vectorizer',v),('classifier',c)])\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "p=model2.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 68  92]\n",
      " [ 91 749]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(p,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.817\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(p, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "print(\"Random Forest Classifier\")\n",
    "r=rfc()\n",
    "model2=Pipeline([('vectorizer',v),('classifier',r)])\n",
    "model2.fit(X_train, y_train)\n",
    "p=model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 59  26]\n",
      " [100 815]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(p,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.874\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(p, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "svc=SVC()\n",
    "model2=Pipeline([('vectorizer',v),('classifier',svc)])\n",
    "model2.fit(X_train, y_train)\n",
    "p=model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 25   3]\n",
      " [134 838]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(p,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.863\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(p, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n",
      "[[ 42  15]\n",
      " [117 826]]\n",
      "0.868\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "estimator = []\n",
    "estimator.append(('LR', \n",
    "                  LogisticRegression(solver ='lbfgs', \n",
    "                                     multi_class ='multinomial', \n",
    "                                     max_iter = 200)))\n",
    "estimator.append(('SVC', SVC(gamma ='auto', probability = True)))\n",
    "estimator.append(('DTC', DecisionTreeClassifier()))\n",
    "  \n",
    "c=VotingClassifier(estimators=estimator,voting='hard')\n",
    "\n",
    "model2=Pipeline([('vectorizer',v),('classifier',c)])\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "p=model2.predict(X_test)\n",
    "print(\"Voting Classifier\")\n",
    "print(confusion_matrix(p,y_test))\n",
    "print(accuracy_score(p, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voting Classifier\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "estimator = []\n",
    "estimator.append(('LR', \n",
    "                  LogisticRegression(solver ='lbfgs', \n",
    "                                     multi_class ='multinomial', \n",
    "                                     max_iter = 200)))\n",
    "estimator.append(('SVC', SVC(gamma ='auto', probability = True)))\n",
    "estimator.append(('DTC', DecisionTreeClassifier()))\n",
    "  \n",
    "c=VotingClassifier(estimators=estimator,voting='soft')\n",
    "\n",
    "model2=Pipeline([('vectorizer',v),('classifier',c)])\n",
    "\n",
    "model2.fit(X_train, y_train)\n",
    "\n",
    "p=model2.predict(X_test)\n",
    "print(\"Voting Classifier\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.871\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(accuracy_score(p, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 57  27]\n",
      " [102 814]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(p,y_test))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
