{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DRASHTI\\.conda\\envs\\tens\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3146: DtypeWarning: Columns (5) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('electronics_small.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>overall</th>\n",
       "      <th>vote</th>\n",
       "      <th>verified</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>67</td>\n",
       "      <td>True</td>\n",
       "      <td>1999-09-18</td>\n",
       "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
       "      <td>A star is born</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>2013-10-23</td>\n",
       "      <td>Pages and pages of introspection, in the style...</td>\n",
       "      <td>A stream of consciousness novel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>2008-09-02</td>\n",
       "      <td>This is the kind of novel to read when you hav...</td>\n",
       "      <td>I'm a huge fan of the author and this one did ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>True</td>\n",
       "      <td>2000-09-04</td>\n",
       "      <td>What gorgeous language! What an incredible wri...</td>\n",
       "      <td>The most beautiful book I have ever read!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>2000-02-04</td>\n",
       "      <td>I was taken in by reviews that compared this b...</td>\n",
       "      <td>A dissenting view--In part.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-07-07</td>\n",
       "      <td>don't work for surface 3</td>\n",
       "      <td>One Star</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-03-13</td>\n",
       "      <td>Good quality cable for Surface RT2 nice video ...</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2018-01-23</td>\n",
       "      <td>The best part of this lens is its close up abi...</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2017-11-09</td>\n",
       "      <td>Solidly built lens with remarkably high defini...</td>\n",
       "      <td>Best bang for the buck out there.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>2016-02-17</td>\n",
       "      <td>Great !!!!</td>\n",
       "      <td>Five Stars</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         overall  vote  verified  reviewTime  \\\n",
       "0              5    67      True  1999-09-18   \n",
       "1              3     5      True  2013-10-23   \n",
       "2              5     4      True  2008-09-02   \n",
       "3              5    13      True  2000-09-04   \n",
       "4              3     8      True  2000-02-04   \n",
       "...          ...   ...       ...         ...   \n",
       "2999995        1     0      True  2017-07-07   \n",
       "2999996        5     0      True  2017-03-13   \n",
       "2999997        5     0      True  2018-01-23   \n",
       "2999998        5     0      True  2017-11-09   \n",
       "2999999        5     0      True  2016-02-17   \n",
       "\n",
       "                                                reviewText  \\\n",
       "0        This is the best novel I have read in 2 or 3 y...   \n",
       "1        Pages and pages of introspection, in the style...   \n",
       "2        This is the kind of novel to read when you hav...   \n",
       "3        What gorgeous language! What an incredible wri...   \n",
       "4        I was taken in by reviews that compared this b...   \n",
       "...                                                    ...   \n",
       "2999995                           don't work for surface 3   \n",
       "2999996  Good quality cable for Surface RT2 nice video ...   \n",
       "2999997  The best part of this lens is its close up abi...   \n",
       "2999998  Solidly built lens with remarkably high defini...   \n",
       "2999999                                         Great !!!!   \n",
       "\n",
       "                                                   summary  \n",
       "0                                           A star is born  \n",
       "1                          A stream of consciousness novel  \n",
       "2        I'm a huge fan of the author and this one did ...  \n",
       "3                The most beautiful book I have ever read!  \n",
       "4                              A dissenting view--In part.  \n",
       "...                                                    ...  \n",
       "2999995                                           One Star  \n",
       "2999996                                         Five Stars  \n",
       "2999997                                         Five Stars  \n",
       "2999998                  Best bang for the buck out there.  \n",
       "2999999                                         Five Stars  \n",
       "\n",
       "[3000000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import sklearn\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "\n",
    "from sklearn import tree\n",
    "\n",
    "\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pickle\n",
    "import os\n",
    "import string\n",
    "import warnings\n",
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "from nltk import tokenize,WordNetLemmatizer, PorterStemmer\n",
    "from nltk.corpus import wordnet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['review','sentiment']]=df[['reviewText','overall']]\n",
    "\n",
    "df=df[['review', 'sentiment']]\n",
    "\n",
    "df['sentiment']=df['sentiment'].replace([1,2,3,4,5],[0,0,0,1,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is the best novel I have read in 2 or 3 y...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pages and pages of introspection, in the style...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the kind of novel to read when you hav...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What gorgeous language! What an incredible wri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was taken in by reviews that compared this b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>don't work for surface 3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>Good quality cable for Surface RT2 nice video ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>The best part of this lens is its close up abi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>Solidly built lens with remarkably high defini...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>Great !!!!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    review  sentiment\n",
       "0        This is the best novel I have read in 2 or 3 y...          1\n",
       "1        Pages and pages of introspection, in the style...          0\n",
       "2        This is the kind of novel to read when you hav...          1\n",
       "3        What gorgeous language! What an incredible wri...          1\n",
       "4        I was taken in by reviews that compared this b...          0\n",
       "...                                                    ...        ...\n",
       "2999995                           don't work for surface 3          0\n",
       "2999996  Good quality cable for Surface RT2 nice video ...          1\n",
       "2999997  The best part of this lens is its close up abi...          1\n",
       "2999998  Solidly built lens with remarkably high defini...          1\n",
       "2999999                                         Great !!!!          1\n",
       "\n",
       "[3000000 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "df['sentiment'].value_counts().plot(kind='bar');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df=df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2999617, 2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "stopwords1 = list(stopwords.words('english'))+list(punctuation) \n",
    "\n",
    "ps=PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "\n",
    "def nltk_tag_to_wordnet_tag(nltk_tag):\n",
    "   \n",
    "    if nltk_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif nltk_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif nltk_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif nltk_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:         \n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i have be work on my skill\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def lemmatize_sentence(sentence):  \n",
    "   \n",
    "    nltk_tagged = nltk.pos_tag(nltk.word_tokenize(sentence)) \n",
    "   \n",
    "    wordnet_tagged = map(lambda x: (x[0], nltk_tag_to_wordnet_tag(x[1])), nltk_tagged)\n",
    "\n",
    "   \n",
    "    lemmatized_sentence = []      \n",
    "    for word, tag in wordnet_tagged:\n",
    "        if tag is None:\n",
    "            lemmatized_sentence.append(word)\n",
    "       \n",
    "        else:       \n",
    "            lemmatized_sentence.append(lemmatizer.lemmatize(word, tag))\n",
    "\n",
    "   \n",
    "    return \" \".join(lemmatized_sentence)\n",
    "\n",
    "print(lemmatize_sentence(\" i have been working on my skills \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Pages and pages of introspection, in the style of writers like Henry James.  I like this kind of  novels and the writer occasionally delights me with her descriptions and observations.  But it\\'s way too repetitious for me and, I think, some parts could have been cut out while still preserving, and probably more tightly crystallizing, the themes and \"truths\" within the story.\\n\\nIt\\'s a story I could relate to but I wish it hadn\\'t been too tedious to read.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pages and page of introspection , in the style of writer like Henry James . I like this kind of novel and the writer occasionally delight me with her description and observation . But it 's way too repetitious for me and , I think , some part could have be cut out while still preserve , and probably more tightly crystallize , the theme and `` truth '' within the story . It 's a story I could relate to but I wish it have n't be too tedious to read .\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(lemmatize_sentence(df['review'][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(a):\n",
    "    return  ' '.join([i.lower() for i in tokenize.word_tokenize(a) if i.lower() not in stopwords1])\n",
    " \n",
    "   \n",
    "    if len(ls)>2:\n",
    "        val= ' '.join(ls)\n",
    "        return val\n",
    "    else :\n",
    "        return None\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text_lemma(a):\n",
    "    val= ' '.join([lemmatizer.lemmatize(i.lower(),pos = 'v') for i in tokenize.word_tokenize(a) if i.lower() not in stopwords1])\n",
    "    return val\n",
    "\n",
    "\n",
    "\n",
    "def clean_text_stem(a):   \n",
    "    val= ' '.join([ps.stem(i.lower()) for i in tokenize.word_tokenize(a) if i.lower() not in stopwords1])\n",
    "    return val\n",
    "\n",
    "df['clean_txt'] = df['review'].apply(clean_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>clean_txt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>best novel read 2 3 years everything fiction -...</td>\n",
       "      <td>1</td>\n",
       "      <td>best novel read 2 3 years everything fiction -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pages pages introspection style writers like h...</td>\n",
       "      <td>0</td>\n",
       "      <td>pages pages introspection style writers like h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kind novel read time lose book days possibly w...</td>\n",
       "      <td>1</td>\n",
       "      <td>kind novel read time lose book days possibly w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>gorgeous language incredible writer last life ...</td>\n",
       "      <td>1</td>\n",
       "      <td>gorgeous language incredible writer last life ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>taken reviews compared book leopard promised b...</td>\n",
       "      <td>0</td>\n",
       "      <td>taken reviews compared book leopard promised b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999995</th>\n",
       "      <td>n't work surface 3</td>\n",
       "      <td>0</td>\n",
       "      <td>n't work surface 3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999996</th>\n",
       "      <td>good quality cable surface rt2 nice video outp...</td>\n",
       "      <td>1</td>\n",
       "      <td>good quality cable surface rt2 nice video outp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999997</th>\n",
       "      <td>best part lens close ability wide angle photog...</td>\n",
       "      <td>1</td>\n",
       "      <td>best part lens close ability wide angle photog...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999998</th>\n",
       "      <td>solidly built lens remarkably high definition ...</td>\n",
       "      <td>1</td>\n",
       "      <td>solidly built lens remarkably high definition ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999999</th>\n",
       "      <td>great</td>\n",
       "      <td>1</td>\n",
       "      <td>great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2999617 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    review  sentiment  \\\n",
       "0        best novel read 2 3 years everything fiction -...          1   \n",
       "1        pages pages introspection style writers like h...          0   \n",
       "2        kind novel read time lose book days possibly w...          1   \n",
       "3        gorgeous language incredible writer last life ...          1   \n",
       "4        taken reviews compared book leopard promised b...          0   \n",
       "...                                                    ...        ...   \n",
       "2999995                                 n't work surface 3          0   \n",
       "2999996  good quality cable surface rt2 nice video outp...          1   \n",
       "2999997  best part lens close ability wide angle photog...          1   \n",
       "2999998  solidly built lens remarkably high definition ...          1   \n",
       "2999999                                              great          1   \n",
       "\n",
       "                                                 clean_txt  \n",
       "0        best novel read 2 3 years everything fiction -...  \n",
       "1        pages pages introspection style writers like h...  \n",
       "2        kind novel read time lose book days possibly w...  \n",
       "3        gorgeous language incredible writer last life ...  \n",
       "4        taken reviews compared book leopard promised b...  \n",
       "...                                                    ...  \n",
       "2999995                                 n't work surface 3  \n",
       "2999996  good quality cable surface rt2 nice video outp...  \n",
       "2999997  best part lens close ability wide angle photog...  \n",
       "2999998  solidly built lens remarkably high definition ...  \n",
       "2999999                                              great  \n",
       "\n",
       "[2999617 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['review']=df['clean_txt']\n",
    "\n",
    "df.dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2399693,) (599924,) (2399693,) (599924,)\n",
      "[ 443712 1955981]\n",
      "[126472 473452]\n"
     ]
    }
   ],
   "source": [
    "df1=df[['review', 'sentiment']]\n",
    "\n",
    "df=df1\n",
    "\n",
    "def simple_split(df,y,l,sm=0.8):\n",
    "    if sm>0 and sm<1.0:\n",
    "        n=int(sm*l)\n",
    "    else:\n",
    "        n=int(sm)\n",
    "    X_train=df[:n].copy()\n",
    "    X_test=df[n:].copy()\n",
    "    y_train=y[:n].copy()\n",
    "    y_test=y[n:].copy()\n",
    "    return X_train,X_test,y_train,y_test\n",
    "        \n",
    "\n",
    "v=CountVectorizer()\n",
    "\n",
    "X_train,X_test,y_train,y_test=simple_split(df.review, df.sentiment, len(df))\n",
    "\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "print(np.bincount(y_train))\n",
    "\n",
    "print(np.bincount(y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression\n"
     ]
    }
   ],
   "source": [
    "print(\"Logistic regression\")\n",
    "clf2=LogisticRegression(solver=\"lbfgs\")\n",
    "model=Pipeline([('vectorizer',v),('classifier',clf2)])\n",
    "model.fit(X_train, y_train)\n",
    "p=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 72916  20448]\n",
      " [ 53556 453004]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(p,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8766443749541608"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(p, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
